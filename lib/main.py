#!/usr/bin/env python3
"""
LLM Stack Manager - Arquitectura Local Nativa
Gesti√≥n simplificada de modelos Ollama para RTX 2070 SUPER

Uso:
    python main.py              # Inicia interfaz interactiva
    python main.py --help       # Muestra ayuda
"""

import sys
from pathlib import Path
import subprocess

from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.text import Text
from rich.prompt import Prompt, Confirm
from rich.progress import Progress, SpinnerColumn, TextColumn

from config_manager import config_manager
from ollama_manager import ollama_manager


class LLMStackApp:
    """Aplicaci√≥n principal para gesti√≥n del stack LLM local."""

    def __init__(self):
        self.console = Console()

    def run(self):
        """Ejecuta el bucle principal de la aplicaci√≥n."""
        while True:
            self._clear_screen()
            self._show_header()
            self._validate_dependencies()
            self._show_menu()

            choice = Prompt.ask("Selecciona una opci√≥n", choices=["1", "2", "3", "4", "5", "6", "7", "8", "0"])

            if choice == "0":
                self._print_success("¬°Hasta luego!")
                break
            elif choice == "1":
                self._validate_installation()
            elif choice == "2":
                self._install_dependencies()
            elif choice == "3":
                self._activate_model()
            elif choice == "4":
                self._deactivate_model()
            elif choice == "5":
                self._update_models()
            elif choice == "6":
                self._check_updates()
            elif choice == "7":
                self._show_status()
            elif choice == "8":
                self._show_config()

            if choice != "0":
                self._wait_for_continue()

    def _clear_screen(self):
        """Limpia la pantalla."""
        self.console.clear()

    def _show_header(self):
        """Muestra el encabezado de la aplicaci√≥n."""
        header = Panel.fit(
            "[bold blue]ü§ñ LLM Stack Manager v0.0.1 - Local Native[/bold blue]\n"
            "[dim]Arquitectura simplificada para RTX 2070 SUPER[/dim]",
            border_style="blue"
        )
        self.console.print(header)
        self.console.print()

    def _validate_dependencies(self):
        """Valida las dependencias del sistema."""
        self.console.print("[bold]Validando Dependencias[/bold]")

        # Verificar Python
        self._print_success(f"Python: {sys.version.split()[0]}")

        # Verificar dependencias Python esenciales (pyyaml se instala autom√°ticamente)
        required_packages = ['rich', 'requests']
        missing_packages = []

        for package in required_packages:
            try:
                __import__(package.replace('-', '_'))
            except ImportError:
                missing_packages.append(package)

        if missing_packages:
            self._print_error(f"Dependencias faltantes: {', '.join(missing_packages)}")
            self._print_info("Usa opci√≥n 2 para instalar autom√°ticamente")
        else:
            self._print_success("Dependencias Python: OK")

        # Verificar Ollama
        if ollama_manager.check_ollama_installed():
            self._print_success("Ollama: OK")
        else:
            self._print_error("Ollama: NO instalado")
            self._print_info("Usa opci√≥n 2 para instalar autom√°ticamente")

        # Verificar configuraci√≥n
        errors = config_manager.validate_config()
        if errors:
            self._print_warning("Configuraci√≥n: Advertencias")
            for error in errors:
                self._print_info(f"  ‚Ä¢ {error}")
        else:
            self._print_success("Configuraci√≥n: OK")

        self.console.print()

    def _show_menu(self):
        """Muestra el men√∫ principal."""
        self.console.print("[bold]Men√∫ Principal:[/bold]")
        self.console.print("  1. üîç Validar Instalaci√≥n Completa")
        self.console.print("  2. üì¶ Instalar Dependencias")
        self.console.print("  3. üü¢ Activar Modelo")
        self.console.print("  4. üõë Desactivar Modelo")
        self.console.print("  5. üì• Actualizar Modelos")
        self.console.print("  6. üîÑ Verificar Actualizaciones")
        self.console.print("  7. ÔøΩ Estado del Sistema")
        self.console.print("  8. ‚öôÔ∏è  Configuraci√≥n")
        self.console.print("  0. üö™ Salir")
        self.console.print()

    def _validate_installation(self):
        """Valida la instalaci√≥n completa."""
        self.console.print("[bold]üîç Validando Instalaci√≥n Completa[/bold]")

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=self.console
        ) as progress:
            task = progress.add_task("Verificando componentes...", total=100)

            # Verificar Python
            progress.update(task, advance=20, description="Python: OK")

            # Verificar dependencias (pyyaml se instala autom√°ticamente)
            required_packages = ['rich', 'requests']
            missing = []
            for package in required_packages:
                try:
                    __import__(package.replace('-', '_'))
                except ImportError:
                    missing.append(package)

            if missing:
                progress.update(task, advance=20, description=f"Dependencias: FALTAN ({len(missing)})")
                self._print_error(f"Dependencias faltantes: {', '.join(missing)}")
                return
            else:
                progress.update(task, advance=20, description="Dependencias: OK")

            # Verificar Ollama
            if ollama_manager.check_ollama_installed():
                progress.update(task, advance=20, description="Ollama: OK")
            else:
                progress.update(task, advance=20, description="Ollama: FALTA")
                self._print_error("Ollama no est√° instalado")
                return

            # Verificar configuraci√≥n
            errors = config_manager.validate_config()
            if errors:
                progress.update(task, advance=20, description="Configuraci√≥n: ADVERTENCIAS")
                self._print_warning("Configuraci√≥n tiene advertencias")
            else:
                progress.update(task, advance=20, description="Configuraci√≥n: OK")

            # Verificar servicio Ollama
            if ollama_manager.check_ollama_running():
                progress.update(task, advance=20, description="Servicio Ollama: ACTIVO")
            else:
                progress.update(task, advance=20, description="Servicio Ollama: INACTIVO")

        self._print_success("‚úÖ Validaci√≥n completa - Sistema listo!")

    def _install_dependencies(self):
        """Instala dependencias autom√°ticamente."""
        self.console.print("[bold]üì¶ Instalando Dependencias[/bold]")

        # Men√∫ de instalaci√≥n
        self.console.print("Selecciona qu√© instalar:")
        self.console.print("  1. Todas las dependencias (recomendado)")
        self.console.print("  2. Solo dependencias Python")
        self.console.print("  3. Solo Ollama")
        self.console.print("  4. Solo entorno virtual")
        self.console.print()

        choice = Prompt.ask("Opci√≥n", choices=["1", "2", "3", "4"], default="1")

        if choice == "1":
            self._install_all_dependencies()
        elif choice == "2":
            self._install_python_deps()
        elif choice == "3":
            self._install_ollama()
        elif choice == "4":
            self._create_venv()

    def _install_all_dependencies(self):
        """Instala todas las dependencias."""
        self.console.print("üöÄ Instalando todas las dependencias...")

        steps = [
            ("Creando entorno virtual", self._create_venv),
            ("Instalando dependencias Python", self._install_python_deps),
            ("Instalando Ollama", self._install_ollama),
        ]

        for step_name, step_func in steps:
            self.console.print(f"üìã {step_name}...")
            if not step_func():
                self._print_error(f"Error en: {step_name}")
                return
            self._print_success(f"{step_name} completado")

        self._print_success("üéâ ¬°Todas las dependencias instaladas!")

    def _create_venv(self):
        """Crea entorno virtual."""
        if Path('.venv').exists():
            self._print_info("Entorno virtual ya existe")
            return True

        try:
            result = subprocess.run([sys.executable, '-m', 'venv', '.venv'], check=True)
            self._print_success("Entorno virtual creado en .venv/")
            return True
        except subprocess.CalledProcessError as e:
            self._print_error(f"Error creando venv: {e}")
            return False

    def _install_python_deps(self):
        """Instala dependencias Python."""
        pip_cmd = '.venv/bin/pip' if Path('.venv/bin/pip').exists() else sys.executable

        try:
            result = subprocess.run([pip_cmd, 'install', '-r', 'requirements.txt'], check=True)
            self._print_success("Dependencias Python instaladas")
            return True
        except subprocess.CalledProcessError as e:
            self._print_error(f"Error instalando dependencias: {e}")
            return False

    def _install_ollama(self):
        """Instala Ollama."""
        if ollama_manager.check_ollama_installed():
            self._print_info("Ollama ya est√° instalado")
            return True

        self.console.print("üì• Descargando e instalando Ollama...")

        try:
            # Descargar script de instalaci√≥n
            result = subprocess.run([
                'curl', '-fsSL', 'https://ollama.com/install.sh'
            ], capture_output=True, text=True, check=True)

            # Ejecutar script
            result2 = subprocess.run(['sh', '-c', result.stdout], check=True)

            self._print_success("Ollama instalado exitosamente")
            return True
        except subprocess.CalledProcessError as e:
            self._print_error(f"Error instalando Ollama: {e}")
            return False

    def _activate_model(self):
        """Activa un modelo."""
        self.console.print("[bold]üü¢ Activando Modelo[/bold]")

        models = config_manager.get_models_list()

        if not models:
            self._print_error("No hay modelos configurados")
            return

        # Mostrar modelos disponibles
        table = Table(title="Modelos disponibles")
        table.add_column("N¬∞", style="cyan", no_wrap=True)
        table.add_column("Modelo", style="green")
        table.add_column("Estado", style="magenta", justify="center")

        running_models = ollama_manager.get_running_models()

        for i, model in enumerate(models, 1):
            status = "üü¢ Activo" if model.name in running_models else "‚ö™ Inactivo"
            table.add_row(str(i), model.name, status)

        self.console.print(table)
        self.console.print()

        choices = [str(i) for i in range(1, len(models) + 1)]
        choice = Prompt.ask("Selecciona modelo para activar", choices=choices)

        try:
            index = int(choice) - 1
            selected_model = models[index]

            with self.console.status(f"Activando {selected_model.name}..."):
                success = ollama_manager.smart_activate_model(list(config_manager.get_models().keys())[index])

            if success:
                self._print_success(f"‚úÖ {selected_model.name} activado exitosamente")
            else:
                self._print_error(f"‚ùå Error activando {selected_model.name}")

        except (ValueError, IndexError):
            self._print_error("Selecci√≥n inv√°lida")

    def _deactivate_model(self):
        """Desactiva un modelo."""
        self.console.print("[bold]üõë Desactivando Modelo[/bold]")

        running = ollama_manager.get_running_models()
        if not running:
            self._print_warning("No hay modelos activos")
            return

        # Mostrar modelos activos
        table = Table(title="Modelos activos")
        table.add_column("N¬∞", style="cyan", no_wrap=True)
        table.add_column("Modelo", style="green")

        for i, model_name in enumerate(running, 1):
            table.add_row(str(i), model_name)

        self.console.print(table)
        self.console.print()

        choices = [str(i) for i in range(1, len(running) + 1)]
        choice = Prompt.ask("Selecciona modelo para desactivar", choices=choices)

        try:
            index = int(choice) - 1
            model_name = running[index]

            with self.console.status(f"Desactivando {model_name}..."):
                success = ollama_manager.stop_model(model_name)

            if success:
                self._print_success(f"‚úÖ {model_name} desactivado - VRAM liberada")
            else:
                self._print_error(f"‚ùå Error desactivando {model_name}")

        except (ValueError, IndexError):
            self._print_error("Selecci√≥n inv√°lida")

    def _check_updates(self):
        """Verifica y aplica actualizaciones de modelos."""
        self.console.print("[bold]üîÑ Verificando Actualizaciones[/bold]")

        with self.console.status("[bold green]Consultando registry de Ollama...") as status:
            updates = ollama_manager.check_model_updates()

        if not updates:
            self._print_success("‚úÖ Todos los modelos est√°n actualizados")
            return

        # Mostrar actualizaciones disponibles
        self.console.print(f"üì¶ {len(updates)} actualizaciones disponibles:")
        self.console.print()

        updates_table = Table(title="Actualizaciones Disponibles")
        updates_table.add_column("Modelo Actual", style="cyan")
        updates_table.add_column("Nueva Versi√≥n", style="green")
        updates_table.add_column("Acci√≥n", style="yellow")

        for model_name, update_info in updates.items():
            updates_table.add_row(
                update_info["current"],
                update_info["latest"],
                "Pendiente"
            )

        self.console.print(updates_table)
        self.console.print()

        # Preguntar qu√© hacer
        self.console.print("Opciones:")
        self.console.print("  1. Actualizar todos los modelos")
        self.console.print("  2. Seleccionar modelos espec√≠ficos")
        self.console.print("  3. Ver detalles de cambios")
        self.console.print("  0. Cancelar")
        self.console.print()

        choice = Prompt.ask("Selecciona una opci√≥n", choices=["1", "2", "3", "0"], default="0")

        if choice == "0":
            self._print_info("Operaci√≥n cancelada")
            return

        elif choice == "1":
            # Actualizar todos
            if Confirm.ask(f"¬øActualizar {len(updates)} modelos?"):
                updated = 0
                for model_name, update_info in updates.items():
                    self.console.print(f"üì• Actualizando {update_info['current']}...")
                    if ollama_manager.update_model_if_available(update_info["current"]):
                        updated += 1
                    else:
                        self._print_error(f"‚ùå Error actualizando {update_info['current']}")

                self._print_success(f"‚úÖ {updated}/{len(updates)} modelos actualizados")

        elif choice == "2":
            # Seleccionar espec√≠ficos
            self.console.print("Modelos disponibles para actualizar:")
            model_list = list(updates.keys())

            for i, model_name in enumerate(model_list, 1):
                update_info = updates[model_name]
                self.console.print(f"  {i}. {update_info['current']} ‚Üí {update_info['latest']}")

            self.console.print()
            try:
                choice = Prompt.ask("N√∫mero del modelo", choices=[str(i) for i in range(1, len(model_list) + 1)])
                index = int(choice) - 1
                selected_model = model_list[index]
                update_info = updates[selected_model]

                if Confirm.ask(f"¬øActualizar {update_info['current']} ‚Üí {update_info['latest']}?"):
                    if ollama_manager.update_model_if_available(update_info["current"]):
                        self._print_success("‚úÖ Modelo actualizado exitosamente")
                    else:
                        self._print_error("‚ùå Error en la actualizaci√≥n")

            except (ValueError, IndexError):
                self._print_error("Selecci√≥n inv√°lida")

        elif choice == "3":
            # Ver detalles (por ahora solo mostrar info b√°sica)
            self.console.print("‚ÑπÔ∏è  Informaci√≥n de actualizaciones:")
            for model_name, update_info in updates.items():
                self.console.print(f"  ‚Ä¢ {update_info['base_name']}: {update_info['current']} ‚Üí {update_info['latest']}")
            self.console.print()
            self._print_info("Las actualizaciones incluyen mejoras de rendimiento, correcci√≥n de bugs y nuevas caracter√≠sticas")

    def _update_models(self):
        """Actualiza modelos."""
        self.console.print("[bold]üì• Actualizando Modelos[/bold]")

        models = config_manager.get_models()

        if Confirm.ask("¬øActualizar todos los modelos instalados?"):
            updated = 0
            for key, model in models.items():
                self.console.print(f"üì• Actualizando {model.name}...")
                if ollama_manager.pull_model(model.name, show_progress=False):
                    self._print_success(f"‚úÖ {model.name} actualizado")
                    updated += 1
                else:
                    self._print_error(f"‚ùå Error actualizando {model.name}")

            self._print_success(f"üìä {updated}/{len(models)} modelos actualizados")
        else:
            self._print_info("Operaci√≥n cancelada")

    def _show_status(self):
        """Muestra estado detallado del sistema."""
        self.console.print("[bold]üìä Estado del Sistema[/bold]")

        status = ollama_manager.get_status_summary()
        vram = ollama_manager.get_vram_usage()

        # Panel de estado
        status_table = Table(title="Estado General")
        status_table.add_column("Componente", style="cyan")
        status_table.add_column("Estado", style="green")

        status_table.add_row("Servicio Ollama", "‚úÖ Activo" if status["ollama_running"] else "‚ùå Inactivo")
        status_table.add_row("Modelos Instalados", f"üì¶ {status['models_installed']}")
        status_table.add_row("Modelos Cargados", f"üß† {status['models_running']}")
        status_table.add_row("VRAM Usada", f"üíæ {vram.used_vram} / {vram.total_vram}")

        if status["models_with_updates"] > 0:
            status_table.add_row("Actualizaciones", f"üîÑ {status['models_with_updates']} disponibles")

        self.console.print(status_table)
        self.console.print()

        # Modelos cargados
        if status["running_models"]:
            running_panel = Panel(
                "\n".join(f"‚Ä¢ {model}" for model in status["running_models"]),
                title="üü¢ Modelos Activos",
                border_style="green"
            )
            self.console.print(running_panel)
            self.console.print()

        # Actualizaciones disponibles
        if status["available_updates"]:
            updates_list = []
            for model_name, update_info in status["available_updates"].items():
                updates_list.append(f"‚Ä¢ {update_info['current']} ‚Üí {update_info['latest']}")

            updates_panel = Panel(
                "\n".join(updates_list),
                title=f"üîÑ {len(status['available_updates'])} Actualizaciones Disponibles",
                border_style="yellow"
            )
            self.console.print(updates_panel)

    def _show_config(self):
        """Muestra configuraci√≥n actual."""
        self.console.print("[bold]‚öôÔ∏è Configuraci√≥n Actual[/bold]")

        config = config_manager.get_config()

        config_table = Table(title="Configuraci√≥n del Sistema")
        config_table.add_column("Opci√≥n", style="cyan")
        config_table.add_column("Valor", style="green")

        config_table.add_row("Directorio configuraci√≥n", str(config_manager.config_dir))
        config_table.add_row("Host Ollama", config.ollama_host)
        config_table.add_row("M√°x modelos simult√°neos", str(config.max_loaded_models))
        config_table.add_row("Auto-stop inactivo", str(config.auto_stop_inactive))
        config_table.add_row("Timeout inactivo (min)", str(config.inactive_timeout_minutes))

        self.console.print(config_table)
        self.console.print()

        # Modelos configurados
        models = config_manager.get_models_list()
        if models:
            models_table = Table(title="Modelos Configurados")
            models_table.add_column("Modelo", style="green")
            models_table.add_column("Descripci√≥n", style="white")

            for model in models:
                models_table.add_row(model.name, model.description)

            self.console.print(models_table)

    def _wait_for_continue(self):
        """Espera a que el usuario presione Enter."""
        self.console.print()
        Prompt.ask("Presiona Enter para continuar")

    def _print_success(self, message: str):
        """Imprime mensaje de √©xito."""
        self.console.print(f"[green]‚úÖ {message}[/green]")

    def _print_error(self, message: str):
        """Imprime mensaje de error."""
        self.console.print(f"[red]‚ùå {message}[/red]")

    def _print_warning(self, message: str):
        """Imprime mensaje de advertencia."""
        self.console.print(f"[yellow]‚ö†Ô∏è  {message}[/yellow]")

    def _print_info(self, message: str):
        """Imprime mensaje informativo."""
        self.console.print(f"[cyan]‚Ñπ {message}[/cyan]")


def show_welcome():
    """Muestra mensaje de bienvenida"""
    print("ü§ñ LLM Stack Manager v0.0.1 - Local Native")
    print("=======================================")
    print("Arquitectura simplificada para desarrollo local")
    print("‚Ä¢ Ollama nativo (sin contenedores)")
    print("‚Ä¢ RTX 2070 SUPER optimizado")
    print("‚Ä¢ Gesti√≥n inteligente de VRAM")
    print()


def main():
    """Funci√≥n principal."""
    try:
        app = LLMStackApp()
        app.run()
    except KeyboardInterrupt:
        print("\nüëã ¬°Hasta luego!")
        sys.exit(0)
    except Exception as e:
        print(f"\n‚ùå Error fatal: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()